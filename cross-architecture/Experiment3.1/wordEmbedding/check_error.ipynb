{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c1602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging batches: 100%|██████████| 7/7 [00:58<00:00,  8.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "OUTPUT_DIR = Path(\"/home/tommy/Projects/cross-architecture/Vector/20250509_test/model\")\n",
    "\n",
    "# 找出所有 batch 檔，並按 batch 編號排序\n",
    "batch_files = sorted(\n",
    "    OUTPUT_DIR.glob(\"sentences_batch_*.pkl\"),\n",
    "    key=lambda p: int(p.stem.split(\"_\")[-1])\n",
    ")\n",
    "\n",
    "all_sentences = []\n",
    "for bf in tqdm(batch_files, desc=\"Merging batches\"):\n",
    "    with open(bf, \"rb\") as f:\n",
    "        sentences = pickle.load(f)\n",
    "    all_sentences.extend(sentences)\n",
    "\n",
    "# 存成最終合併檔\n",
    "final_path = OUTPUT_DIR / \"sentences_all_20250509_test.pkl\"\n",
    "with open(final_path, \"wb\") as f:\n",
    "    pickle.dump(all_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d87b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tommy/Projects/Gpickle/2050509/benign/00/00a745912aa7f9bdbae2683f5249fe2222514d65d218b923a0cca0d300f2f4f2.gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/tommy/Projects/Gpickle/2050509/benign/00/00a745912aa7f9bdbae2683f5249fe2222514d65d218b923a0cca0d300f2f4f2.gpickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     G \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(G)\n",
      "File \u001b[0;32m~/miniconda3/envs/cross-architecture/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tommy/Projects/Gpickle/2050509/benign/00/00a745912aa7f9bdbae2683f5249fe2222514d65d218b923a0cca0d300f2f4f2.gpickle'"
     ]
    }
   ],
   "source": [
    "\n",
    "# check G pickle\n",
    "import pickle\n",
    "\n",
    "path = \"/home/tommy/Projects/cross-architecture/Gpickle/2050509/benign/00/00a745912aa7f9bdbae2683f5249fe2222514d65d218b923a0cca0d300f2f4f2.gpickle\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "print(G)\n",
    "\n",
    "node = list(G.nodes)[0]  \n",
    "print(f\"\\n節點 {node} 的屬性:\")\n",
    "print(G.nodes[node])\n",
    "\n",
    "edge = list(G.edges)[0]\n",
    "print(f\"\\n邊 {edge} 的屬性:\")\n",
    "print(G.edges[edge])\n",
    "\n",
    "#Check KEY\n",
    "node_keys = set()\n",
    "for node, attrs in G.nodes(data=True):\n",
    "    node_keys.update(attrs.keys())\n",
    "\n",
    "print(f\"節點屬性 Keys: {list(node_keys)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f925f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph named 'code' with 115 nodes and 219 edges\n",
      "\n",
      "節點 0x102000 的屬性:\n",
      "{'label': '\"_init\"', 'x': tensor([ 1.0070e+00,  2.0768e-01,  4.4592e-01,  9.6419e-01, -3.4525e-02,\n",
      "         1.5223e-01, -1.3945e-01, -4.4620e-01,  7.7939e-01, -1.0715e-01,\n",
      "         1.6683e-01,  4.5647e-01, -7.2403e-02,  2.7262e-01, -4.4680e-01,\n",
      "        -8.8046e-01, -2.3111e-01, -2.7058e-01, -3.1520e-01, -9.0320e-01,\n",
      "         4.2199e-02,  3.8400e-01,  3.5017e-01, -6.3076e-01,  6.1247e-01,\n",
      "         8.4713e-04,  9.3877e-03,  5.6567e-01,  1.3309e-01,  2.1933e-01,\n",
      "         4.9007e-01,  1.2919e-01, -3.3424e-01,  1.8737e-01, -1.0289e-01,\n",
      "         1.6006e-01,  2.2681e-01,  8.7138e-01, -5.7162e-02, -8.0651e-02,\n",
      "         4.0634e-01,  7.2284e-01,  2.5383e-01,  5.6373e-02,  3.9396e-04,\n",
      "         3.4813e-01, -3.3003e-02, -7.4331e-02,  1.9375e-01, -3.3841e-01,\n",
      "        -5.6892e-01, -4.0609e-01,  2.3443e-01, -3.4564e-01,  6.7484e-01,\n",
      "        -2.0818e-01,  6.2905e-02, -2.8883e-01,  3.2628e-01,  4.2303e-01,\n",
      "        -1.8101e-01, -2.4812e-01,  1.6886e-01, -2.9829e-01,  8.2777e-01,\n",
      "        -3.3014e-01,  1.9449e-01,  3.6079e-01, -3.0820e-01,  9.8645e-01,\n",
      "         5.0430e-01,  3.1239e-01,  5.0228e-01, -2.9788e-01, -9.4061e-02,\n",
      "         6.6304e-01, -2.5085e-01,  5.5321e-01, -1.5035e-01, -3.5315e-01,\n",
      "         1.6932e-01, -3.7986e-01,  2.2655e-01,  1.4948e-02, -4.3163e-01,\n",
      "         2.4942e-01,  7.3501e-01,  8.6906e-01,  4.9710e-02,  1.0668e-01,\n",
      "         2.8231e-02, -8.7038e-01, -1.0691e-01,  7.9139e-01, -1.3555e-01,\n",
      "         8.7426e-01, -1.0492e+00, -6.3116e-01, -1.8006e-01,  8.2469e-02,\n",
      "        -8.8342e-01,  1.2924e-01,  2.1583e-01, -1.3847e-01,  3.0029e-01,\n",
      "         5.5814e-01,  3.2883e-01,  2.9489e-01,  4.6458e-01,  7.2198e-01,\n",
      "        -4.7025e-01,  5.8155e-01, -9.5010e-01, -7.4171e-01,  3.7677e-01,\n",
      "        -2.3333e-01, -4.6945e-01, -7.7192e-01,  4.1819e-01,  1.7862e-01,\n",
      "        -6.7329e-01,  1.6346e-01,  1.3522e-01, -1.4941e-02, -5.5354e-01,\n",
      "        -1.9738e-01,  7.0915e-02, -3.2431e-01])}\n",
      "\n",
      "邊 ('0x102000', '0x10f128', 0) 的屬性:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "path2= \"/home/tommy/Projects/cross-architecture/Experiment3.1/wordEmbedding/0a0b2846b78d5b8e36c5571efbdd13b2eac9a8aacf597d2b9799c7d05af8f163.gpickle\"\n",
    "\n",
    "with open(path2, \"rb\") as f:\n",
    "    G2 = pickle.load(f)\n",
    "print(G2)\n",
    "node2 = list(G2.nodes)[0]\n",
    "print(f\"\\n節點 {node2} 的屬性:\")\n",
    "print(G2.nodes[node2])\n",
    "edge2 = list(G2.edges)[0]\n",
    "print(f\"\\n邊 {edge2} 的屬性:\")\n",
    "print(G2.edges[edge2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ae52a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 87 nodes and 131 edges\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "file_path = \"/home/tommy/Projects/cross-architecture/Vector/20250509_train/benign/00/00a745912aa7f9bdbae2683f5249fe2222514d65d218b923a0cca0d300f2f4f2.gpickle\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    G2 = pickle.load(f)\n",
    "print(G2)\n",
    "print()\n",
    "# node2 = list(G2.nodes)[0]\n",
    "# print(f\"\\n節點 {node2} 的屬性:\")\n",
    "# print(G2.nodes[node2])\n",
    "# edge2 = list(G2.edges)[0]\n",
    "# print(f\"\\n邊 {edge2} 的屬性:\")\n",
    "# print(G2.edges[edge2])\n",
    "# print(type(G2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7bd273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 87 nodes and 131 edges\n",
      "Data(edge_index=[2, 131], x=[87, 256])\n",
      "tensor([[ 0.0089,  0.0800,  0.0570,  ..., -0.1141, -0.0775, -0.0682],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0540, -0.0107, -0.0752,  ...,  0.1620, -0.0584,  0.0526],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0,  0,  0,  0,  7,  7,  7,  7,  7,  7, 14, 17, 19, 19, 19, 19, 19, 19,\n",
      "         19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 31, 32, 32,\n",
      "         33, 33, 34, 34, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 37, 37,\n",
      "         37, 37, 37, 37, 37, 37, 37, 37, 39, 39, 39, 39, 50, 50, 50, 50, 50, 50,\n",
      "         50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 60, 60, 60, 60,\n",
      "         60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 64, 64, 64, 64, 66, 66, 66, 66,\n",
      "         66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 70,\n",
      "         70, 70, 72, 83, 83],\n",
      "        [ 1,  2,  3,  4,  8,  9, 10, 11, 12, 13,  5, 18, 20, 21, 22, 23, 24, 25,\n",
      "         26,  1, 27, 28,  3, 29, 30, 31,  0, 32, 33, 34, 35, 36, 37, 69, 20,  0,\n",
      "         20,  0, 20,  0, 20, 62, 24,  1,  0, 20, 25, 38, 31, 39,  0, 15, 40, 41,\n",
      "         42, 43, 44, 45, 46, 47, 48, 49, 20, 25, 38, 31, 21, 51, 52, 53, 54, 55,\n",
      "         56, 57, 58, 59, 26, 27, 46, 48, 49, 19, 60, 61,  6,  7, 20, 62, 23, 24,\n",
      "          1, 63, 31,  0, 32, 33, 34, 35, 36, 37, 65, 66, 67, 68, 74,  9, 55, 75,\n",
      "         76, 77, 78, 79,  1, 80,  3, 81, 71, 82, 70, 83,  7, 50, 72, 17, 14, 52,\n",
      "          9, 71, 73, 85, 86]])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "print(G2)\n",
    "node2 = list(G2.nodes)[0]\n",
    "data = from_networkx(G2, group_node_attrs=['vector'])\n",
    "print(data)\n",
    "print(data.x)\n",
    "print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eedd82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'from_networkx' from 'torch_geometric' (/home/tommy/miniconda3/envs/cross-architecture/lib/python3.12/site-packages/torch_geometric/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_networkx\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/tommy/Projects/cross-architecture/Vector/20250509_train/malware/02/0231fc6c11109f9f4eaa1dad40d2fbe64607dd84891a3ed72d23e01f2c2005a4.gpickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'from_networkx' from 'torch_geometric' (/home/tommy/miniconda3/envs/cross-architecture/lib/python3.12/site-packages/torch_geometric/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "from torch_geometric.utils import from_networkx\n",
    "path = \"/home/tommy/Projects/cross-architecture/Vector/20250509_train/malware/02/0231fc6c11109f9f4eaa1dad40d2fbe64607dd84891a3ed72d23e01f2c2005a4.gpickle\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    G3 = pickle.load(f)\n",
    "\n",
    "data = from_networkx(G3, group_node_attrs=['vector'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a76a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 222 nodes and 578 edges\n",
      "{}\n",
      "['0x00011c1c', '0x000116fc', '0x0001198c', '0x00012b88', '0x00012ca0', '0x000141f0', '0x00014668', '0x000146bc', '0x000164fc', '0x00013884', '0x00011350', '0x00015bec', '0x0000816c', '0x00008190', '0x00010a18', '0x00013090', '0x000115fc', '0x00015c5c', '0x0000d9f8', '0x00010640', '0x000113ec', '0x00012d44', '0x00013100', '0x00014508', '0x00015b3c', '0x00012ba0', '0x00014730', '0x0000860c', '0x000087c0', '0x0000a694', '0x0000ad40', '0x0000afd0', '0x0000b260', '0x000116a8', '0x00012864', '0x000113cc', '0x0001403c', '0x0000d824', '0x0000fc60', '0x0000fc84', '0x0000fd24', '0x000105ac', '0x00010ca4', '0x00014024', '0x00013a88', '0x00013980', '0x00015b44', '0x00013ab0', '0x00013f08', '0x000161b4', '0x00016138', '0x00016218', '0x00011690', '0x00012f54', '0x00012e34', '0x00013a3c', '0x0001350c', '0x0001412c', '0x00010aac', '0x00010ba8', '0x00014168', '0x00015258', '0x00012db0', '0x00016108', '0x00013624', '0x000135a8', '0x000135dc', '0x000162c0', '0x00011564', '0x00017e30', '0x00014928', '0x000150e8', '0x00016c24', '0x00013550', '0x0000dac4', '0x0001061c', '0x00012118', '0x0000fdc4', '0x00017e38', '0x000081cc', '0x0000859c', '0x0000d760', '0x000105d4', '0x00010664', '0x000106d0', '0x00010908', '0x00010998', '0x00010de8', '0x00012dd4', '0x00012df8', '0x00012f7c', '0x00012fb4', '0x00013020', '0x00013dbc', '0x000144d0', '0x000145f4', '0x0000cb68', '0x0000d9d0', '0x0001360c', '0x00017ed0', '0x00017158', '0x000147b8', '0x0001474c', '0x00015f08', '0x000140c8', '0x00012e0c', '0x00014198', '0x000141bc', '0x00012fd8', '0x00013a60', '0x000138ec', '0x000136b8', '0x00013670', '0x00017770', '0x00016684', '0x000175cc', '0x00017240', '0x00017460', '0x00017e14', '0x000186a4', '0x0000dc2c', '0x0000b8dc', '0x0000b92c', '0x0000d7bc', '0x00010868', '0x00011368', '0x00012fa0', '0x00013044', '0x00013264', '0x00015d58', '0x0000d8f4', '0x00012d1c', '0x00010cbc', '0x00010e00', '0x000080c8', '0x00015df4', '0x0000cd80', '0x0000bad4', '0x00010e14', '0x000131f4', '0x0001320c', '0x00013848', '0x00015bb8', '0x00012c64', '0x0001514c', '0x000165d8', '0x000165f4', '0x000186b8', '0x000080b4', '0x00015698', '0x0001108c', '0x00013958', '0x000142d4', '0x00015c10', '0x00016084', '0x00013260', '0x00013574', '0x00015e54', '0x00015e34', '0x00016120', '0x00017f14', '0x000171a4', '0x0000810c', '0x00014354', '0x000143c4', '0x000130d4', '0x00014910', '0x0000ba00', '0x00008530', '0x00011630', '0x00015d20', '0x0001663c', '0x00008228', '0x00014570', '0x00015dc0', '0x00014584', '0x0000b9d8', '0x00012a40', '0x00015e30', '0x0001432c', '0x00013a18', '0x00014330', '0x000130b4', '0x00014458', '0x000132f0', '0x000134cc', '0x00015830', '0x00015b88', '0x00015b94', '0x00008324', '0x00012b50', '0x0001455c', '0x0000cba0', '0x0000c5d8', '0x00014628', '0x00013900', '0x00012810', '0x00015288', '0x00011040', '0x00012d88', '0x00013694', '0x000145dc', '0x00015514', '0x00012ba4', '0x000178b4', '0x00015868', '0x00011138', '0x00011134', '0x000161f8', '0x0001405c', '0x00011010', '0x000156b8', '0x0001080c', '0x000145c4', '0x00012cd8', '0x00011364', '0x00016260', '0x00016240', '0x0000ce00', '0x00018670', '0x00017228', '0x00014504']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "path = \"/home/tommy/Projects/cross-architecture/Vector/20250509_train/malware/00/0060772874e12dcd8e589d42ad4672aa0eb830d434f45c9c7b213d7f1481d4ad.gpickle\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "print(G)              # 先看節點/邊數量\n",
    "print(G.graph)        # 如果有全域屬性\n",
    "print(G.nodes)        # 看所有節點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e9981ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 52 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     G \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_networkx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/cross-architecture/lib/python3.12/site-packages/torch_geometric/utils/convert.py:275\u001b[0m, in \u001b[0;36mfrom_networkx\u001b[0;34m(G, group_node_attrs, group_edge_attrs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[0;32m--> 275\u001b[0m         data_dict[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 52 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "path = \"/home/tommy/Projects/cross-architecture/Experiment3.1/wordEmbedding/0a0b2846b78d5b8e36c5571efbdd13b2eac9a8aacf597d2b9799c7d05af8f163.gpickle\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "data = from_networkx(G)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dfcbcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發現異常節點數：0\n",
      "前 10 筆範例： []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "bad_nodes = []\n",
    "\n",
    "for n, attrs in G.nodes(data=True):\n",
    "    # 先拿 vector；拿不到再拿 x，**不要用 or**\n",
    "    if \"vector\" in attrs:\n",
    "        vec = attrs[\"vector\"]\n",
    "    else:\n",
    "        vec = attrs.get(\"x\")   # 可能拿到 None\n",
    "\n",
    "    # 以下照舊檢查 vec\n",
    "    if vec is None:\n",
    "        bad_nodes.append((n, \"missing\"))\n",
    "        continue\n",
    "    if isinstance(vec, (list, str)):\n",
    "        bad_nodes.append((n, type(vec).__name__))\n",
    "        continue\n",
    "    if isinstance(vec, np.ndarray) and not np.issubdtype(vec.dtype, np.number):\n",
    "        bad_nodes.append((n, f\"ndarray<{vec.dtype}>\"))\n",
    "\n",
    "print(f\"發現異常節點數：{len(bad_nodes)}\")\n",
    "print(\"前 10 筆範例：\", bad_nodes[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6fab5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 131], x=[87, 256])\n"
     ]
    }
   ],
   "source": [
    "data = from_networkx(G2, group_node_attrs=['vector'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23a897df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "tensor(-0.9216, dtype=torch.float64) tensor(0.6495, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(data.x.dtype)          # 應該是 torch.float32\n",
    "print(data.x.min(), data.x.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73738764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 349], x=[87, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "tfm = T.Compose([\n",
    "    T.ToUndirected(),\n",
    "    T.NormalizeFeatures(),\n",
    "    T.AddSelfLoops(),\n",
    "])\n",
    "\n",
    "data_t = tfm(data)           # 無錯即可\n",
    "print(data_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4cdeef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檢查完畢，問題檔案數：0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle, networkx as nx\n",
    "import numpy as np, torch\n",
    "\n",
    "def check_gpickle(path, vector_dim=256):\n",
    "    with open(path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    for n, attr in G.nodes(data=True):\n",
    "        vec = attr.get(\"vector\", attr.get(\"x\"))\n",
    "        if vec is None:                               # 缺向量\n",
    "            return False, n, \"missing\"\n",
    "        if isinstance(vec, (list, str)):\n",
    "            return False, n, type(vec).__name__\n",
    "        if isinstance(vec, np.ndarray) and (vec.size != vector_dim or not np.issubdtype(vec.dtype, np.number)):\n",
    "            return False, n, f\"ndarray<{vec.dtype}>\"\n",
    "    return True, None, None\n",
    "\n",
    "root = Path(\"/home/tommy/Projects/cross-architecture/Vector/20250509_train\")\n",
    "bad_files = []\n",
    "for p in root.rglob(\"*.gpickle\"):\n",
    "    ok, nid, info = check_gpickle(p)\n",
    "    if not ok:\n",
    "        bad_files.append((p, nid, info))\n",
    "\n",
    "print(f\"檢查完畢，問題檔案數：{len(bad_files)}\")\n",
    "for f, nid, info in bad_files[:10]:\n",
    "    print(f, \"節點:\", nid, \"原因:\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b342984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning nodes: 100%|██████████| 129/129 [00:00<00:00, 926481.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 節點屬性統計 ===\n",
      "vector               129\n",
      "\n",
      "=== 找到 list[str] 屬性 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm  # optional\n",
    "\n",
    "# 1. 找出屬性名稱 → 出現次數\n",
    "node_attr_counter = Counter()\n",
    "liststr_nodes = defaultdict(list)   # attr_name -> [(node_id, list_len), ...]\n",
    "\n",
    "for n, attrs in tqdm(G2.nodes(data=True), desc=\"Scanning nodes\"):\n",
    "    for k, v in attrs.items():\n",
    "        # 統計型別\n",
    "        node_attr_counter[k] += 1\n",
    "\n",
    "        # 判斷是否為 list[str]\n",
    "        if isinstance(v, list) and all(isinstance(x, str) for x in v):\n",
    "            liststr_nodes[k].append((n, len(v)))\n",
    "\n",
    "print(\"=== 節點屬性統計 ===\")\n",
    "for attr, cnt in node_attr_counter.most_common():\n",
    "    print(f\"{attr:20} {cnt}\")\n",
    "\n",
    "print(\"\\n=== 找到 list[str] 屬性 ===\")\n",
    "for attr, nodes in liststr_nodes.items():\n",
    "    print(f\"* {attr}: {len(nodes)} 個節點\")\n",
    "    # 只示範列印前 5 個\n",
    "    for nid, ln in nodes[:5]:\n",
    "        print(f\"  - node {nid}, length={ln}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3876ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU: ARM\n",
      "  Family benign: 1922 samples\n",
      "  Family dofloo: 182 samples\n",
      "  Family gafgyt: 1249 samples\n",
      "  Family hajime: 45 samples\n",
      "  Family kaiji: 93 samples\n",
      "  Family meterpreter: 70 samples\n",
      "  Family mirai: 1706 samples\n",
      "  Family mobidash: 68 samples\n",
      "  Family tsunami: 809 samples\n",
      "  Family wroba: 52 samples\n",
      "\n",
      "CPU: Advanced Micro Devices X86-64\n",
      "  Family benign: 1851 samples\n",
      "  Family dofloo: 49 samples\n",
      "  Family gafgyt: 1977 samples\n",
      "  Family hajime: 1 samples\n",
      "  Family kaiji: 54 samples\n",
      "  Family meterpreter: 157 samples\n",
      "  Family mirai: 1677 samples\n",
      "  Family mobidash: 12 samples\n",
      "  Family tsunami: 1871 samples\n",
      "  Family wroba: 10 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Check CPU by family\n",
    "file_path = \"/home/tommy/Projects/cross-architecture/Experiment3.1/dataset/20250509_train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "cpu_family_counts = df.groupby(['CPU', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# 輸出每個 CPU 中各 family 的數量\n",
    "for cpu in cpu_family_counts['CPU'].unique():\n",
    "    print(f\"\\nCPU: {cpu}\")\n",
    "    cpu_data = cpu_family_counts[cpu_family_counts['CPU'] == cpu]\n",
    "    for _, row in cpu_data.iterrows():\n",
    "        print(f\"  Family {row['label']}: {row['count']} samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70eb413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU: ARM\n",
      "  Family benign: 1853 samples\n",
      "  Family dofloo: 77 samples\n",
      "  Family gafgyt: 1245 samples\n",
      "  Family hajime: 25 samples\n",
      "  Family kaiji: 81 samples\n",
      "  Family meterpreter: 40 samples\n",
      "  Family mirai: 1697 samples\n",
      "  Family mobidash: 68 samples\n",
      "  Family tsunami: 808 samples\n",
      "  Family wroba: 52 samples\n",
      "\n",
      "CPU: Advanced Micro Devices X86-64\n",
      "  Family benign: 1848 samples\n",
      "  Family dofloo: 38 samples\n",
      "  Family gafgyt: 1974 samples\n",
      "  Family hajime: 1 samples\n",
      "  Family kaiji: 54 samples\n",
      "  Family meterpreter: 71 samples\n",
      "  Family mirai: 1677 samples\n",
      "  Family mobidash: 12 samples\n",
      "  Family tsunami: 1868 samples\n",
      "  Family wroba: 9 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/home/tommy/Projects/cross-architecture/Experiment3.1/dataset/cleaned_20250509_train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "cpu_family_counts = df.groupby(['CPU', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# 輸出每個 CPU 中各 family 的數量\n",
    "for cpu in cpu_family_counts['CPU'].unique():\n",
    "    print(f\"\\nCPU: {cpu}\")\n",
    "    cpu_data = cpu_family_counts[cpu_family_counts['CPU'] == cpu]\n",
    "    for _, row in cpu_data.iterrows():\n",
    "        print(f\"  Family {row['label']}: {row['count']} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41bd072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU: MIPS R3000\n",
      "  Family benign: 2237 samples\n",
      "  Family dofloo: 43 samples\n",
      "  Family gafgyt: 1186 samples\n",
      "  Family kaiji: 175 samples\n",
      "  Family meterpreter: 30 samples\n",
      "  Family mirai: 1605 samples\n",
      "  Family mobidash: 140 samples\n",
      "  Family tsunami: 772 samples\n",
      "  Family wroba: 45 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/home/tommy/Projects/cross-architecture/Experiment3.1/dataset/cleaned_20250509_test.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "cpu_family_counts = df.groupby(['CPU', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# 輸出每個 CPU 中各 family 的數量\n",
    "for cpu in cpu_family_counts['CPU'].unique():\n",
    "    print(f\"\\nCPU: {cpu}\")\n",
    "    cpu_data = cpu_family_counts[cpu_family_counts['CPU'] == cpu]\n",
    "    for _, row in cpu_data.iterrows():\n",
    "        print(f\"  Family {row['label']}: {row['count']} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-architecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
